{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Filter out warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from scipy import stats\n",
    "import math\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FOR STATISTICAL ANALYSIS\n",
    "# Create a Combined Dataframe from message csv and orderbook csv\n",
    "def Merge_MsgAndOrdb(msg_path, ordb_path):\n",
    "    # get the level of the LOBSTER dataset\n",
    "    level = int(msg_path.split(\".\")[0][-1])\n",
    "    # get the date\n",
    "    date = msg_path.split(\".\")[0].split(\"_\")[1]\n",
    "\n",
    "    # add header row for message csv\n",
    "    msg_names = [\"Time_stamp\", \"Type\", \"OrderID\", \"V\", \"P\", \"Dir\"]  # V: size; P: price; Dir: direction\n",
    "    df_msg = pd.read_csv(msg_path, names=msg_names)\n",
    "    # add header row for orderbook csv\n",
    "    default_ordb_names = ['P_ask', 'V_ask', 'P_bid', 'V_bid']\n",
    "    ordb_names = []\n",
    "    for i in range(level):\n",
    "        for item in default_ordb_names:\n",
    "            ordb_names.append(str(item) + str(\"_\") + str(i + 1))\n",
    "    df_ordb = pd.read_csv(ordb_path, names=ordb_names)\n",
    "\n",
    "    # adding a meaningful time column\n",
    "    df_msg['Time'] = pd.to_datetime(df_msg['Time_stamp'], unit=\"s\", origin=pd.Timestamp(date))\n",
    "\n",
    "    # combine two dataframes and return it\n",
    "    df = pd.concat([df_msg, df_ordb], axis=1)\n",
    "    return df\n",
    "\n",
    "# Renaming columns as to strip out redundnat words\n",
    "def RenameColumn(df,state_type):\n",
    "    old_col = df.columns.tolist()\n",
    "    new_col = []\n",
    "    for col in old_col:\n",
    "        if ( (\"bid\" in col) | (\"ask\" in col) ):\n",
    "            new_col.append(col+str(\" \")+state_type)\n",
    "        elif ((col == 'V') | (col == 'P')):\n",
    "            new_col.append(col+str(\" \")+state_type)\n",
    "        elif (col=='Time'):\n",
    "            new_col.append(col+str(\" \")+state_type)\n",
    "        else:\n",
    "            new_col.append(col)\n",
    "    columns = dict(zip(old_col,new_col))\n",
    "    df.rename(columns=columns,inplace=True)\n",
    "    return\n",
    "\n",
    "def GroupByOrderType(df,typeID):                        # for now, typeID should only be 2 or 3 or 4 or 5\n",
    "    # lookup dictionary\n",
    "    lookup = {1:'Sub', 2:'Can', 3:'Del', 4:'ExVis',5:'ExHid',7:'Halt'}\n",
    "    # getting all the orders of type typeID\n",
    "    orderID_set = set(df[(df['Type']==typeID)].OrderID.tolist())\n",
    "    df_subset = df.loc[df['OrderID'].isin(orderID_set)]\n",
    "    \n",
    "    # get initial states when orders of this type is submitted\n",
    "    df_init = df_subset[(df_subset['Type']==1)]\n",
    "    RenameColumn(df_init,state_type=lookup[1])\n",
    "    \n",
    "    # get the end states of type typeID\n",
    "    df_end = df_subset[(df_subset['Type']==typeID)]\n",
    "    RenameColumn(df_end,state_type=lookup[typeID])\n",
    "    \n",
    "    # merge these two dataframes\n",
    "    df = df_init.merge(df_end, left_on='OrderID', right_on='OrderID', how='outer')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FOR PAPER 462\n",
    "# Compute Time-insensitive variables\n",
    "def ComputeTimeInsenstiveSet(df_original, levels=5):\n",
    "    df = df_original.copy(deep=False)\n",
    "    for i in range(1,levels+1):\n",
    "        # compute bid-ask spreads and mid-prices (v2)\n",
    "        df[\"bid-ask spread {}\".format(i)] = df[\"P_ask_{}\".format(i)] - df[\"P_bid_{}\".format(i)]\n",
    "        df[\"mid-price {}\".format(i)] = (df[\"P_ask_{}\".format(i)] + df[\"P_bid_{}\".format(i)])/2\n",
    "        # compute price differences (v3)\n",
    "        df[\"d_P_ask_{}{}\".format(levels,1)] = df[\"P_ask_{}\".format(levels)] - df[\"P_ask_1\"]\n",
    "        df[\"d_P_bid_{}{}\".format(levels,1)] = df[\"P_bid_{}\".format(levels)] - df[\"P_bid_1\"]\n",
    "        for j in range(1,levels):\n",
    "            df[\"d_P_ask_{}{}\".format(j+1,j)] = np.abs(df[\"P_ask_{}\".format(j+1)] - df[\"P_ask_{}\".format(j)])\n",
    "            df[\"d_P_bid_{}{}\".format(j+1,j)] = np.abs(df[\"P_bid_{}\".format(j+1)] - df[\"P_bid_{}\".format(j)])\n",
    "        # compute mean prices and volumes (v4)\n",
    "        df[\"Mean_P_ask\"] = df[[\"P_ask_{}\".format(i) for i in range(1,levels+1)]].mean(axis=1)\n",
    "        df[\"Mean_P_bid\"] = df[[\"P_bid_{}\".format(i) for i in range(1,levels+1)]].mean(axis=1)\n",
    "        df[\"Mean_V_ask\"] = df[[\"V_ask_{}\".format(i) for i in range(1,levels+1)]].mean(axis=1)\n",
    "        df[\"Mean_V_bid\"] = df[[\"V_bid_{}\".format(i) for i in range(1,levels+1)]].mean(axis=1)\n",
    "        # compute accumulated differences (v5)\n",
    "        df[\"P_accu\"] = df[[\"P_ask_{}\".format(i) for i in range(1,levels+1)]].sum(axis=1) \\\n",
    "            - df[[\"P_bid_{}\".format(i) for i in range(1,levels+1)]].sum(axis=1)\n",
    "        df[\"V_accu\"] = df[[\"V_ask_{}\".format(i) for i in range(1,levels+1)]].sum(axis=1) \\\n",
    "            - df[[\"V_bid_{}\".format(i) for i in range(1,levels+1)]].sum(axis=1)\n",
    "    # returning...\n",
    "    return df\n",
    "\n",
    "# Compute Time-sensitive variables\n",
    "def ComputeTimeSensitiveSet(df_original,levels=5,dt_secs=1):\n",
    "    df = df_original.copy(deep=False)\n",
    "    #\n",
    "    for index, row in df.iterrows():\n",
    "        t = row['Time_stamp']\n",
    "        temp = df.loc[(df['Time_stamp']>t-dt_secs)&(df['Time_stamp']<=t)] # for v6\n",
    "        # Note: direction = 1 <--> buy/bid order;   direction = -1 <--> sell/ask order\n",
    "        temp_la = df.loc[(df['Time_stamp']>t-dt_secs)&(df['Time_stamp']<=t)&(df['Dir']==-1)] # limit ask order\n",
    "        temp_lb = df.loc[(df['Time_stamp']>t-dt_secs)&(df['Time_stamp']<=t)&(df['Dir']==1)]  # limit bid order\n",
    "        temp_ca = df.loc[(df['Time_stamp']>t-dt_secs)&(df['Time_stamp']<=t)\n",
    "                         &(df['Dir']==-1)&(df['Type']==2)] # cancelled limit ask order\n",
    "        temp_cb = df.loc[(df['Time_stamp']>t-dt_secs)&(df['Time_stamp']<=t)\n",
    "                         &(df['Dir']==1)&(df['Type']==2)]  # cancelled limit buy order\n",
    "        for i in range(1,levels+1):\n",
    "            # compute price and volume derivatives (v6)\n",
    "            df.set_value(index,'der_P_ask_{}'.format(i),\n",
    "                         (temp['P_ask_{}'.format(i)].iloc[-1]-temp['P_ask_{}'.format(i)].iloc[0])/dt_secs)\n",
    "            df.set_value(index,'der_P_bid_{}'.format(i),\n",
    "                         (temp['P_bid_{}'.format(i)].iloc[-1]-temp['P_bid_{}'.format(i)].iloc[0])/dt_secs)\n",
    "            df.set_value(index,'der_V_ask_{}'.format(i),\n",
    "                         (temp['V_ask_{}'.format(i)].iloc[-1]-temp['V_ask_{}'.format(i)].iloc[0])/dt_secs)\n",
    "            df.set_value(index,'der_V_bid_{}'.format(i),\n",
    "                         (temp['V_bid_{}'.format(i)].iloc[-1]-temp['V_bid_{}'.format(i)].iloc[0])/dt_secs)\n",
    "            # compute average intensity of each type (v7)\n",
    "            df.set_value(index,'lam_la',int(len(temp_la.index)/dt_secs))\n",
    "            df.set_value(index,'lam_lb',int(len(temp_lb.index)/dt_secs))\n",
    "            df.set_value(index,'lam_ca',int(len(temp_ca.index)/dt_secs))\n",
    "            df.set_value(index,'lam_cb',int(len(temp_cb.index)/dt_secs))\n",
    "            # compute relative intensity indicators (v8) ???\n",
    "            # compute accelerations (market/limit)  (v9) ???\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_stamp</th>\n",
       "      <th>Type</th>\n",
       "      <th>OrderID</th>\n",
       "      <th>V</th>\n",
       "      <th>P</th>\n",
       "      <th>Dir</th>\n",
       "      <th>Time</th>\n",
       "      <th>P_ask_1</th>\n",
       "      <th>V_ask_1</th>\n",
       "      <th>P_bid_1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_bid_3</th>\n",
       "      <th>V_bid_3</th>\n",
       "      <th>P_ask_4</th>\n",
       "      <th>V_ask_4</th>\n",
       "      <th>P_bid_4</th>\n",
       "      <th>V_bid_4</th>\n",
       "      <th>P_ask_5</th>\n",
       "      <th>V_ask_5</th>\n",
       "      <th>P_bid_5</th>\n",
       "      <th>V_bid_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34200.017460</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2238200</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-06-21 09:30:00.017460</td>\n",
       "      <td>2239500</td>\n",
       "      <td>100</td>\n",
       "      <td>2231800</td>\n",
       "      <td>...</td>\n",
       "      <td>2230400</td>\n",
       "      <td>100</td>\n",
       "      <td>2242500</td>\n",
       "      <td>100</td>\n",
       "      <td>2230000</td>\n",
       "      <td>10</td>\n",
       "      <td>2244000</td>\n",
       "      <td>547</td>\n",
       "      <td>2226200</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34200.189608</td>\n",
       "      <td>1</td>\n",
       "      <td>11885113</td>\n",
       "      <td>21</td>\n",
       "      <td>2238100</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-21 09:30:00.189608</td>\n",
       "      <td>2239500</td>\n",
       "      <td>100</td>\n",
       "      <td>2238100</td>\n",
       "      <td>...</td>\n",
       "      <td>2230700</td>\n",
       "      <td>200</td>\n",
       "      <td>2242500</td>\n",
       "      <td>100</td>\n",
       "      <td>2230400</td>\n",
       "      <td>100</td>\n",
       "      <td>2244000</td>\n",
       "      <td>547</td>\n",
       "      <td>2230000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34200.189608</td>\n",
       "      <td>1</td>\n",
       "      <td>3911376</td>\n",
       "      <td>20</td>\n",
       "      <td>2239600</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-06-21 09:30:00.189608</td>\n",
       "      <td>2239500</td>\n",
       "      <td>100</td>\n",
       "      <td>2238100</td>\n",
       "      <td>...</td>\n",
       "      <td>2230700</td>\n",
       "      <td>200</td>\n",
       "      <td>2240000</td>\n",
       "      <td>220</td>\n",
       "      <td>2230400</td>\n",
       "      <td>100</td>\n",
       "      <td>2242500</td>\n",
       "      <td>100</td>\n",
       "      <td>2230000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34200.189608</td>\n",
       "      <td>1</td>\n",
       "      <td>11534792</td>\n",
       "      <td>100</td>\n",
       "      <td>2237500</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-21 09:30:00.189608</td>\n",
       "      <td>2239500</td>\n",
       "      <td>100</td>\n",
       "      <td>2238100</td>\n",
       "      <td>...</td>\n",
       "      <td>2231800</td>\n",
       "      <td>100</td>\n",
       "      <td>2240000</td>\n",
       "      <td>220</td>\n",
       "      <td>2230700</td>\n",
       "      <td>200</td>\n",
       "      <td>2242500</td>\n",
       "      <td>100</td>\n",
       "      <td>2230400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34200.189608</td>\n",
       "      <td>1</td>\n",
       "      <td>1365373</td>\n",
       "      <td>13</td>\n",
       "      <td>2240000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012-06-21 09:30:00.189608</td>\n",
       "      <td>2239500</td>\n",
       "      <td>100</td>\n",
       "      <td>2238100</td>\n",
       "      <td>...</td>\n",
       "      <td>2231800</td>\n",
       "      <td>100</td>\n",
       "      <td>2240000</td>\n",
       "      <td>233</td>\n",
       "      <td>2230700</td>\n",
       "      <td>200</td>\n",
       "      <td>2242500</td>\n",
       "      <td>100</td>\n",
       "      <td>2230400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time_stamp  Type   OrderID    V        P  Dir                       Time  \\\n",
       "0  34200.017460     5         0    1  2238200   -1 2012-06-21 09:30:00.017460   \n",
       "1  34200.189608     1  11885113   21  2238100    1 2012-06-21 09:30:00.189608   \n",
       "2  34200.189608     1   3911376   20  2239600   -1 2012-06-21 09:30:00.189608   \n",
       "3  34200.189608     1  11534792  100  2237500    1 2012-06-21 09:30:00.189608   \n",
       "4  34200.189608     1   1365373   13  2240000   -1 2012-06-21 09:30:00.189608   \n",
       "\n",
       "   P_ask_1  V_ask_1  P_bid_1   ...     P_bid_3  V_bid_3  P_ask_4  V_ask_4  \\\n",
       "0  2239500      100  2231800   ...     2230400      100  2242500      100   \n",
       "1  2239500      100  2238100   ...     2230700      200  2242500      100   \n",
       "2  2239500      100  2238100   ...     2230700      200  2240000      220   \n",
       "3  2239500      100  2238100   ...     2231800      100  2240000      220   \n",
       "4  2239500      100  2238100   ...     2231800      100  2240000      233   \n",
       "\n",
       "   P_bid_4  V_bid_4  P_ask_5  V_ask_5  P_bid_5  V_bid_5  \n",
       "0  2230000       10  2244000      547  2226200      100  \n",
       "1  2230400      100  2244000      547  2230000       10  \n",
       "2  2230400      100  2242500      100  2230000       10  \n",
       "3  2230700      200  2242500      100  2230400      100  \n",
       "4  2230700      200  2242500      100  2230400      100  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Merge_MsgAndOrdb(msg_path='AMZN_2012-06-21_34200000_57600000_message_5.csv',\n",
    "                     ordb_path='AMZN_2012-06-21_34200000_57600000_orderbook_5.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the labels (lb, la, mb, ma) to classify all of the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 155935\n",
      "65000 out of 155935\n",
      "130000 out of 155935\n"
     ]
    }
   ],
   "source": [
    "total = len(df.index)\n",
    "labels = []\n",
    "for index, row in df.iterrows():\n",
    "    if (((index)%65000 == 0)):\n",
    "        print(index, \"out of\", total)\n",
    "    if (row[\"Type\"] == 1):\n",
    "        if (row[\"Dir\"] == -1):\n",
    "            labels.append('la')\n",
    "        elif (row[\"Dir\"] == 1):\n",
    "            labels.append('lb')\n",
    "    elif (row[\"Type\"] in [4, 5]):\n",
    "        if (row[\"Dir\"] == -1):\n",
    "            labels.append('mb')\n",
    "        elif (row[\"Dir\"] == 1):\n",
    "            labels.append('ma')\n",
    "    elif (row[\"Type\"] == 2):\n",
    "        labels.append('pc')\n",
    "    elif (row[\"Type\"] == 3):\n",
    "        labels.append('c')\n",
    "    else:\n",
    "        labels.append(None)\n",
    "\n",
    "df[\"Labels\"] = labels\n",
    "#print(len(labels), total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the level where action takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check = False\n",
    "nlevels = 5\n",
    "levels = [None]\n",
    "for index, row in df.iterrows():\n",
    "    if (index > 0):\n",
    "        bid_levels = np.array(df.iloc[index-1][[\"P_bid_{}\".format(i) for i in range(1,nlevels+1)]])\n",
    "        ask_levels = np.array(df.iloc[index-1][[\"P_ask_{}\".format(i) for i in range(1,nlevels+1)]])\n",
    "        \n",
    "        price = row[\"P\"]\n",
    "        if (row[\"Labels\"] == 'c'):\n",
    "            if (row[\"Dir\"] == -1):\n",
    "                index = np.where(price == ask_levels)[0]\n",
    "                levels.append(int(index+1))\n",
    "            elif (row[\"Dir\"] == 1):\n",
    "                index = np.where(price == bid_levels)[0]\n",
    "                levels.append(int(index+1))\n",
    "            else:\n",
    "                ### Some error here\n",
    "                print(\"idk\")\n",
    "                break\n",
    "        else:\n",
    "            levels.append(None)\n",
    "    \n",
    "df[\"Level\"] = levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ask = Counter(df[(df['Labels']=='c') & (df['Dir'] == -1)][\"Level\"])\n",
    "buy = Counter(df[(df['Labels']=='c') & (df['Dir'] == 1)][\"Level\"])\n",
    "buy = buy[::-1]\n",
    "for i in range(5):\n",
    "    plt.bar(i, buy[i])\n",
    "for i in range(5,11):\n",
    "    plt.bar(i, ask[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(df[\"Labels\"])\n",
    "print(counts)\n",
    "print(\"{:0.1f}%\".format(100*counts['c']/(counts['la'] + counts['lb'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oids = list(set(df[\"OrderID\"]))\n",
    "from collections import Counter\n",
    "#print(Counter(oids).most_common(100))\n",
    "\n",
    "for oid in oids[1:]:\n",
    "    history = df[df[\"OrderID\"] == oid]\n",
    "    if (len(history.index) > 2):\n",
    "        break\n",
    "\n",
    "print(\"Immediately Before:\")\n",
    "print(\"Bid:\", df.iloc[107887][\"P_bid_1\"]/1e5, df.iloc[107887][\"V_bid_1\"])\n",
    "print(\"Ask:\", df.iloc[107887][\"P_ask_1\"]/1e5, df.iloc[107887][\"V_ask_1\"])\n",
    "# print(\"Order:\", history.iloc[17888][\"P\"]/1e5, history.iloc[17888][\"V\"], history.iloc[1][\"Dir\"])\n",
    "\n",
    "print(\"\\nCurrently:\")\n",
    "print(\"Bid:\", history.iloc[1][\"P_bid_1\"]/1e5, history.iloc[1][\"V_bid_1\"])\n",
    "print(\"Ask:\", history.iloc[1][\"P_ask_1\"]/1e5, history.iloc[1][\"V_ask_1\"])\n",
    "print(\"Order:\", history.iloc[1][\"P\"]/1e5, history.iloc[1][\"V\"], history.iloc[1][\"Dir\"])\n",
    "history[[\"OrderID\",\"Type\",\"P\",\"V\",\"Dir\",\"P_bid_1\",\"V_bid_1\",\"P_ask_1\",\"V_ask_1\",\"Labels\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are all of the deleted orders fully deleted??\n",
    "##### YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find = 0\n",
    "for oid in oids[1:]:\n",
    "    history = df[df[\"OrderID\"] == oid]\n",
    "    labels = list(history[\"Labels\"])\n",
    "    if (('c' in labels) and (labels.count('c') > 2)):\n",
    "#         find += 1\n",
    "#         if (find == 2):\n",
    "#             break\n",
    "        break\n",
    "        \n",
    "history[[\"OrderID\",\"Type\",\"P\",\"V\",\"Dir\",\"P_bid_1\",\"V_bid_1\",\"P_ask_1\",\"V_ask_1\",\"Labels\"]].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = [\"OrderID\", \"P\", \"Dir\", \"bV\", \"dV\", \"bLevel\", \"dLevel\", \"bLabel\", \"dLabel\"]\n",
    "\n",
    "uoids = []\n",
    "for oid in oids[1:]:\n",
    "    history = df[df[\"OrderID\"] == oid].reset_index()\n",
    "    birth = history.iloc[0]\n",
    "    death = history.iloc[-1]\n",
    "    uoids.append([oid, birth[\"P\"], birth[\"Dir\"], birth[\"V\"], death[\"V\"], ])\n",
    "    break\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sens = ComputeTimeInsenstiveSet(df)\n",
    "# df_sens.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sensInsens = ComputeTimeSensitiveSet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sensInsens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
